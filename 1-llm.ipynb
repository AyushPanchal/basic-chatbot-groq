{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4dcf591",
   "metadata": {},
   "source": [
    "## 0. Add dependencies to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-groq langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9d4b2",
   "metadata": {},
   "source": [
    "## 1. Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4391ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# If we want to use chats with OpenAI models, we can use the following import\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# In this case, we would also need to set the OPENAI_API_KEY environment variable in `.env` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53990123",
   "metadata": {},
   "source": [
    "## 2. Import environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77624b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe1430",
   "metadata": {},
   "source": [
    "## 3. Initialize the ChatGroq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db7c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446cb6f3",
   "metadata": {},
   "source": [
    "## 4. Define the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4e8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba41748",
   "metadata": {},
   "source": [
    "## 5. Create the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b0f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f00271",
   "metadata": {},
   "source": [
    "## 6. Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b73c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is the capital of India?\"\n",
    "question = \"Explain LLM like I'm 5.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9597156",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eddcdc",
   "metadata": {},
   "source": [
    "## 7. Print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909d71a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh boy, are you going to love this!\n",
      "\n",
      "So, you know how you can talk to me and I can understand what you're saying? Like, if you say \"I like ice cream,\" I know what that means.\n",
      "\n",
      "A LLM, or Large Language Model, is like a super smart computer that can understand and talk back to people too. It's like a robot that can have conversations with you.\n",
      "\n",
      "Imagine you have a magic box that can answer any question you ask it. You can say \"What's the best kind of ice cream?\" and the box will say \"Chocolate!\" or \"Strawberry!\" or something like that.\n",
      "\n",
      "The magic box (or LLM) has been taught by reading a HUGE amount of words and conversations, so it knows how to talk and understand language really well. It's like a super smart friend that can help you with anything you need!\n",
      "\n",
      "But instead of being a real person, it's just a computer program that can talk and understand language. Isn't that cool?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe412c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-groq-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
